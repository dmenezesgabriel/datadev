{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207e423a",
   "metadata": {},
   "source": [
    "# Glue Spark\n",
    "\n",
    "- RDD: Datasets which storage data in distributed format\n",
    "- Transformations: Datasets iterations\n",
    "- Actions: Run the transformations on RDD\n",
    "- Output data: Result of transformations\n",
    "\n",
    "Spark runs lazy, so transformations are not immediately executed, they stay in a logical plan to be executed when the actions are called.\n",
    "\n",
    "Actions examples:\n",
    "\n",
    "- `take()`\n",
    "- `collect()`\n",
    "- `show()`\n",
    "- `save()`\n",
    "- `count()`\n",
    "\n",
    "## Types of transformations\n",
    "\n",
    "### Narrow\n",
    "\n",
    "Act only on one partition of the output data (Map, Filter)\n",
    "\n",
    "- Does not requires to share data within another workers\n",
    "- Are independent of other partitions\n",
    "- Are computationally efficient\n",
    "\n",
    "### Wide\n",
    "\n",
    "Can work on several partitions of output data (Join, GroupBy)\n",
    "\n",
    "## Running locally\n",
    "\n",
    "1. Docker Compose file:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  glue:\n",
    "    image: amazon/aws-glue-libs:glue_libs_4.0.0_image_01\n",
    "    container_name: glue-jupyter\n",
    "    ports:\n",
    "      - \"8889:8888\"\n",
    "      - \"4040:4040\"\n",
    "    volumes:\n",
    "      - .:/home/glue_user/workspace/jupyter_workspace\n",
    "      - ~/.aws:/home/glue_user/.aws:ro\n",
    "    working_dir: /home/glue_user/workspace\n",
    "    environment:\n",
    "      AWS_PROFILE: default\n",
    "      DISABLE_SSL: true\n",
    "    command: >\n",
    "      /home/glue_user/jupyter/jupyter_start.sh\n",
    "```\n",
    "\n",
    "2. Run image:\n",
    "\n",
    "```sh\n",
    "docker compose run --rm glue\n",
    "```\n",
    "\n",
    "3. Connect to jupyter server within vscode:\n",
    "\n",
    "- Select kernel\n",
    "- Existing jupyter server\n",
    "- https://127.0.1:8889/lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b8cff",
   "metadata": {},
   "source": [
    "Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed2dd6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd6ab5e0ebf4b58813d8d2b706a352f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc54e1",
   "metadata": {},
   "source": [
    "Create session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd5ec8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5398ede353f477f8788f865fab89917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c2c83",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "Create a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cee167",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4278f6b7753d40c79f2708da8c3fac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    (\"John\", \"Sales\", 3000),\n",
    "    (\"Bryan\", \"Sales\", 4200),\n",
    "    (\"Selena\", \"Sales\", 4600),\n",
    "    (\"Alice\", \"Sales\", 3500),\n",
    "    (\"Mark\", \"Sales\", 3900),\n",
    "    (\"Sophia\", \"Sales\", 4100),\n",
    "    (\"Daniel\", \"Sales\", 3800),\n",
    "    (\"Emma\", \"Sales\", 4400),\n",
    "    (\"Lucas\", \"Sales\", 3600),\n",
    "    (\"Olivia\", \"Sales\", 4700),\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"name\", \"department\", \"salary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9f438",
   "metadata": {},
   "source": [
    "Visualize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d55b6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe1a1326a6647869c40eb2187217ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+\n",
      "|  name|department|salary|\n",
      "+------+----------+------+\n",
      "|  John|     Sales|  3000|\n",
      "| Bryan|     Sales|  4200|\n",
      "|Selena|     Sales|  4600|\n",
      "| Alice|     Sales|  3500|\n",
      "|  Mark|     Sales|  3900|\n",
      "|Sophia|     Sales|  4100|\n",
      "|Daniel|     Sales|  3800|\n",
      "|  Emma|     Sales|  4400|\n",
      "| Lucas|     Sales|  3600|\n",
      "|Olivia|     Sales|  4700|\n",
      "+------+----------+------+"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893aaaf9",
   "metadata": {},
   "source": [
    "Filtering dataset (narrow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6aa789",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95928a40c38442bb857bfa66cdf8a8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+\n",
      "|  name|department|salary|\n",
      "+------+----------+------+\n",
      "| Bryan|     Sales|  4200|\n",
      "|Selena|     Sales|  4600|\n",
      "|Sophia|     Sales|  4100|\n",
      "|  Emma|     Sales|  4400|\n",
      "|Olivia|     Sales|  4700|\n",
      "+------+----------+------+"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(df[\"salary\"] > 4000)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263eb20d",
   "metadata": {},
   "source": [
    "Group By (Wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def64b74",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b34355b31314c13a1ac1aec60d3cd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|     Sales|   10|\n",
      "+----------+-----+"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(\"department\").count()\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9b0cb",
   "metadata": {},
   "source": [
    "## Pushdown Predicate\n",
    "\n",
    "Reduce the total data read applying conditional filters to the data columns.\n",
    "\n",
    "- Depends on file formats (Parquet and ORC)\n",
    "\n",
    "1. Query submitted to spark\n",
    "2. Planning phase using Catalyst optimizer\n",
    "3. Filters identification (predicate)\n",
    "4. Pushdown: try to bring the filter to reading\n",
    "\n",
    "Using pure spark `WHERE` clause is enough, when using _AWS Glue_, `pushdown_predicate` argument is needed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
