{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1b8217",
   "metadata": {},
   "source": [
    "# RAG - Vector Search with Qdrant\n",
    "\n",
    "```sh\n",
    "docker run --rm --name qdrant\\\n",
    "     -p 6333:6333 \\\n",
    "     -p 6334:6334 \\\n",
    "     -v \"${PWD}/qdrant_storage:/qdrant/storage:z\" \\\n",
    "     qdrant/qdrant:v1.16.3\n",
    "```\n",
    "\n",
    "Go to http://localhost:6333/dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1967e",
   "metadata": {},
   "source": [
    "Install packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6600ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q \\\n",
    "    requests==2.32.5 \\\n",
    "    python-dotenv==1.2.1 \\\n",
    "    litellm==1.78.5 \\\n",
    "    qdrant-client==1.16.2 \\\n",
    "    fastembed==0.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae09c36",
   "metadata": {},
   "source": [
    "Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0eb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import litellm\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4bb45",
   "metadata": {},
   "source": [
    "Download documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c12c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_url = \"https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json\"\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course[\"course\"]\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cd926",
   "metadata": {},
   "source": [
    "Create a Qdrant client instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc1ac1",
   "metadata": {},
   "source": [
    "Verify models compatible with current setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09286dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89cc82",
   "metadata": {},
   "source": [
    "Choose model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bab78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c73f3",
   "metadata": {},
   "source": [
    "Define a collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550d50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "if qd_client.collection_exists(collection_name=collection_name):\n",
    "    qd_client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY, distance=models.Distance.COSINE\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7d7b4",
   "metadata": {},
   "source": [
    "Create points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae182190",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=models.Document(text=doc[\"text\"], model=model_handle),\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            },\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e431a",
   "metadata": {},
   "source": [
    "Generate embeddings and insert into Qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82280ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(collection_name=collection_name, points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(text=query, model=model_handle),\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721673dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Validation dataset helps to validate models and prediction on unseen data. This helps get an estimate on its performance on fresh data. It helps optimize the model.\\nEdidiong Esu\\nBelow is an extract of Alexey's book explaining this point. Hope is useful\\nWhen we apply the fit method, this method is looking at the content of the df_train dictionaries we are passing to the DictVectorizer instance, and fit is figuring out (training) how to map the values of these dictionaries. If categorical, applies one-hot encoding, if numerical it will leave it as it is.\\nWith this context, if we apply the fit to the validation model, we are \\\"giving the answers\\\" and we are not letting the \\\"fit\\\" do its job for data that we haven't seen. By not applying the fit to the validation model we can know how well it was trained.\\nBelow is an extract of Alexey's book explaining this point.\\nHumberto Rodriguez\\nThere is no need to initialize another instance of dictvectorizer after fitting it on the train set as it will overwrite what it learnt from being fit on the train data.\\nThe correct way is to fit_transform the train set, and only transform the validation and test sets.\\nMemoona Tahira\",\n",
      "  \"section\": \"3. Machine Learning for Classification\",\n",
      "  \"question\": \"Fitting DictVectorizer on validation\",\n",
      "  \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=529, version=1, score=0.86013603, payload={'text': 'Validation dataset helps to validate models and prediction on unseen data. This helps get an estimate on its performance on fresh data. It helps optimize the model.\\nEdidiong Esu\\nBelow is an extract of Alexey\\'s book explaining this point. Hope is useful\\nWhen we apply the fit method, this method is looking at the content of the df_train dictionaries we are passing to the DictVectorizer instance, and fit is figuring out (training) how to map the values of these dictionaries. If categorical, applies one-hot encoding, if numerical it will leave it as it is.\\nWith this context, if we apply the fit to the validation model, we are \"giving the answers\" and we are not letting the \"fit\" do its job for data that we haven\\'t seen. By not applying the fit to the validation model we can know how well it was trained.\\nBelow is an extract of Alexey\\'s book explaining this point.\\nHumberto Rodriguez\\nThere is no need to initialize another instance of dictvectorizer after fitting it on the train set as it will overwrite what it learnt from being fit on the train data.\\nThe correct way is to fit_transform the train set, and only transform the validation and test sets.\\nMemoona Tahira', 'section': '3. Machine Learning for Classification', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search(course_piece[\"question\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909e83f",
   "metadata": {},
   "source": [
    "Index fields that will be used as filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0634c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=3, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab00db",
   "metadata": {},
   "source": [
    "Search with filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e24fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course, limit=1):\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(text=query, model=model_handle),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\", match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810abcbb",
   "metadata": {},
   "source": [
    "Apply filters in search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b58b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-engineering-zoomcamp\n",
      " No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n",
      "machine-learning-zoomcamp\n",
      " Depends on whether the form will still be open. If you're lucky and it's open, you can submit your homework and it will be evaluated. if closed - it's too late.\n",
      "(Added by Rileen Sinha, based on answer by Alexey on Slack)\n",
      "mlops-zoomcamp\n",
      " Please choose the closest one to your answer. Also do not post your answer in the course slack channel.\n"
     ]
    }
   ],
   "source": [
    "for course in [\n",
    "    \"data-engineering-zoomcamp\",\n",
    "    \"machine-learning-zoomcamp\",\n",
    "    \"mlops-zoomcamp\",\n",
    "]:\n",
    "    print(\n",
    "        course + \"\\n\",\n",
    "        search_in_course(\n",
    "            \"What if I submit homeworks late?\",\n",
    "            course=course,\n",
    "        )\n",
    "        .points[0]\n",
    "        .payload[\"text\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e0220",
   "metadata": {},
   "source": [
    "## RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dac49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"zoomcamp-faq\"\n",
    "\n",
    "if qd_client.collection_exists(collection_name=collection_name):\n",
    "    qd_client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY, distance=models.Distance.COSINE\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705596a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(id=i, vector=vector, payload=doc)\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=3, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(collection_name=collection_name, points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f44fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    course = \"data-engineering-zoomcamp\"\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(text=question, model=model_handle),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\", match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query: str, search_results: List[Dict[str, Any]]):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the question based on the CONTEXT.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = (\n",
    "            context\n",
    "            + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt: str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    completion = litellm.completion(\n",
    "        model=\"gemini/gemini-2.5-flash\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49380da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka components, the context provides several methods:\n",
      "\n",
      "*   **For Java producers/consumers/kstreams:** In the project directory, run:\n",
      "    `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`\n",
      "\n",
      "*   **For Python producers (e.g., producer.py):**\n",
      "    1.  Create a virtual environment (if not already done): `python -m venv env`\n",
      "    2.  Activate the environment: `source env/bin/activate` (for MacOS/Linux, or `env/Scripts/activate` for Windows)\n",
      "    3.  Install requirements: `pip install -r ../requirements.txt`\n",
      "    4.  Then run your Python file within this activated environment.\n",
      "    Remember to activate the virtual environment every time you need to use it.\n",
      "\n",
      "**To ensure the Kafka broker (the underlying service) is running:**\n",
      "If you encounter a `kafka.errors.NoBrokersAvailable` error, it likely means your Kafka broker docker container is not working. You can start all instances by navigating to the docker compose yaml file folder and running `docker compose up -d`. The context also notes that for Python scripts, Docker images should first all be up and running.\n"
     ]
    }
   ],
   "source": [
    "print(rag(\"how do I run kafka?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-3.11",
   "language": "python",
   "name": "uv-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
