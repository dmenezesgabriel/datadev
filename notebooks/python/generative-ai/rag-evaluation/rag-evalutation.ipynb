{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b61381",
   "metadata": {},
   "source": [
    "# RAG Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f17ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q \\\n",
    "    requests==2.32.5 \\\n",
    "    python-dotenv==1.2.1 \\\n",
    "    tqdm==4.67.1 \\\n",
    "    litellm==1.78.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da2224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import litellm\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b5460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_url = \"https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json\"\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course[\"course\"]\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08276905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc[\"id\"] = generate_document_id(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95211e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': '0bbf41ec'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a354fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947, 948)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes = defaultdict(list)\n",
    "\n",
    "for doc in documents:\n",
    "    doc_id = doc[\"id\"]\n",
    "    hashes[doc_id].append(doc)\n",
    "\n",
    "len(hashes), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593f7569 2\n"
     ]
    }
   ],
   "source": [
    "for k, v in hashes.items():\n",
    "    if len(v) > 1:\n",
    "        print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"They both do the same, it's just less typing from the script.\\nAsked by Andrew Katoch, Added by Edidiong Esu\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'},\n",
       " {'text': \"They both do the same, it's just less typing from the script.\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes[\"593f7569\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94109d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents-with-ids.json\", \"wt\") as f_out:\n",
    "    json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e37ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
      "    \"section\": \"General course-related questions\",\n",
      "    \"question\": \"Course - When will the course start?\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"id\": \"c02e79ef\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites\",\n"
     ]
    }
   ],
   "source": [
    "!head documents-with-ids.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf995b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a student who's taking a course.\n",
    "Formulate 5 questions you might ask based on a FAQ record. The record should\n",
    "contain the answer to the questions, and the questions should be complete and\n",
    "not too short.\n",
    "If possible, use a fewer words as possible from the record.\n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", \"question3\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175d1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling c5396e06af29: 100% ▕██████████████████▏ 397 MB                         \u001b[K\n",
      "pulling 66b9ea09bd5b: 100% ▕██████████████████▏   68 B                         \u001b[K\n",
      "pulling eb4402837c78: 100% ▕██████████████████▏ 1.5 KB                         \u001b[K\n",
      "pulling 832dd9e00a68: 100% ▕██████████████████▏  11 KB                         \u001b[K\n",
      "pulling 005f95c74751: 100% ▕██████████████████▏  490 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!docker exec -it ollama ollama pull qwen2.5:0.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab986d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            ID              SIZE      MODIFIED      \n",
      "qwen2.5:0.5b    a8b0c5157701    397 MB    7 minutes ago    \n"
     ]
    }
   ],
   "source": [
    "!docker exec -it ollama ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dc7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are a class of pre-trained neural network models widely used for tasks such as image and speech recognition. They are characterized by their self-attention mechanism, which enables them to process input data not only through the sequence (as seen in word-level processing) but also at different levels of abstraction, resulting in improved downstream performance compared to their predecessors. Transformers build upon a series of components including positional encoding, multi-head attention, and feedforward networks. Their architecture is similar to RNNs or LSTMs with additional layers that maintain state information as they pass through the model. This allows them to handle complex sequence tasks more efficiently than traditional models by enabling them to automatically learn patterns in long sequences without needing explicit token-by-token processing. Additionally, Transformers can be fine-tuned on small datasets at a scale much larger than what was previously feasible, making their use case for smaller language models and other applications where they perform better than existing approaches is clear.\n"
     ]
    }
   ],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"ollama/qwen2.5:0.5b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain transformers in one paragraph.\"},\n",
    "    ],\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\",\n",
    "    custom_llm_provider=\"ollama\",\n",
    ")\n",
    "\n",
    "print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11493c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=\"ollama/qwen2.5:0.5b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        api_base=\"http://localhost:11434\",\n",
    "        api_key=\"ollama\",\n",
    "        custom_llm_provider=\"ollama\",\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1080bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(\"generated_questions.json\")\n",
    "\n",
    "if OUTPUT_PATH.exists():\n",
    "    with OUTPUT_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba239c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(data, path=OUTPUT_PATH):\n",
    "    tmp_path = path.with_suffix(\".tmp\")\n",
    "    with tmp_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    tmp_path.replace(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/948 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    doc_id = str(doc[\"id\"])\n",
    "\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    results[doc_id] = questions\n",
    "\n",
    "    save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-3.11",
   "language": "python",
   "name": "uv-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
